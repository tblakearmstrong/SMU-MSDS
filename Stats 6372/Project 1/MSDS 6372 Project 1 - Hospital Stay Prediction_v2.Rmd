---
title: 'MSDS 6371 Project 1: Hospital Stay MLR'
author: "Tracy Dower & Blake Armstrong"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Dataset & Objectives

This is an R Markdown document. For more information on the team and this analysis including the raw dataset, final presentation, and link to video presentation please visit our GitHub repository <https://github.com/tblakearmstrong/SMU-MSDS/tree/main/Stats%206372/Project%201>.

The team chose to analyze the provided dataset of hospital data that contains 11 predictors collected from 113 different hospitals. There are two main objectives here that the team has set out to solve that we have outlined below:

  **Objective 1:** This analysis is to determine whether a hospital's *__infection risk__* is significantly associated with the *__average length__* of patient stay, after accounting for other potentially influential factors. Using data from 113 hospitals—including variables such as patient age, number of nurses, hospital utilization, number of beds, and frequency of routine medical checks—we will construct a regression model to evaluate the impact of infection risk and related factors on hospital stay duration.
  
  **Objective 2:** The goal of this phase is to develop a predictive model that *__estimates patient length of stay as accurately as possible__*. Building on the initial regression model from Objective 1, we will fit two additional models:

  1. A more *__complex Multiple Linear Regression (MLR)__* model that includes added features or interactions.

    \Number two will need to be updated with the model that we went with\

  2. A *__nonparametric model__*, such as k-Nearest Neighbors (KNN), a regression tree, or a random forest, utilizing tools available in the caret package.

  3. All three models will be evaluated using an appropriate error metric (e.g., RMSE or MAE), and the results will be summarized in a comparison table. Based on model performance, a recommendation will be made regarding which model is best suited for predicting future patient hospital stays.


### Exploratory Data Analysis (EDA)

In EDA we attempt to visually identify trends and such that we can verify important insights and assumptions about the data.
This process involves summarizing the main characteristics of a dataset, often using visual methods such as histograms, boxplots, scatter plots, and correlation matrices. EDA helps uncover underlying patterns, spot anomalies or outliers, test assumptions, and check the quality of the data. It is a crucial first step before applying any formal modeling techniques, as it guides data cleaning, feature selection, and the choice of analytical methods.

First we want to upload the data and determine if there are any missing variables that we need to account for.  From the chart, it looks like the dataset we were provided is not missing any data points, and the corresponding variable summaries and value histograms can be observed as well:

```{r datainput, echo =FALSE, message = FALSE, warning = FALSE}
library(naniar)
library(skimr)
library(dplyr)

set.seed(123)

data.link <-"https://raw.githubusercontent.com/tblakearmstrong/SMU-MSDS/refs/heads/main/Stats%206372/Project%201/HospitalDurations.csv"
hospital <- read.csv(data.link, header =TRUE)

hospital <- hospital %>% 
  mutate(across(everything(), log, .names = "log_{.col}") %>% 
  select(-1,-8,-9))
  
#Look at data
skim.hospital <- hospital %>%
  select(-matches("log", ignore.case = TRUE)) %>%
  rename(
    "Length of Stay" = Lgth.of.Sty,
    "Infection Risk" = Inf.Risk,
    "Routine Culturing Ratio" = R.Cul.Rat,
    "Routine Chest X-Ray Ratio" = R.CX.ray.Rat,
    "No. of Beds" = N.Beds,
    "Med School Affiliation" = Med.Sc.Aff,
    "Average Patients" = Avg.Pat,
    "Average Full Time Nurses" = Avg.Nur,
    "Percent Facility Utilization" = Pct.Ser.Fac
  )

skim(skim.hospital)
```

Next, we want to look for trends between our response variable and the predictor variables:

  **Linear-Linear Plots:** From the plots below, there looks to be decent clustering in a couple of the plots therefore we will explore transforming them to see how trends change.  Additionally, two predictors, "Med School Affiliation" and "Region" could be treated as categorical variables, however there is an observed trend in Region that we would consider not treating it as such.  

```{r testplots, echo = FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)

set.seed(123)

response <- "Lgth.of.Sty"
predictors <- c("Age", "Inf.Risk", "R.Cul.Rat", "R.CX.ray.Rat", "N.Beds", "Avg.Pat", "Avg.Nur", "Pct.Ser.Fac", "Med.Sc.Aff", "Region")

label_map <- c(
  Age = "Patient Age",
  Inf.Risk = "Infection Risk",
  R.Cul.Rat = "Routine Culturing Ratio",
  R.CX.ray.Rat = "Routine Chest X-Ray Ratio",
  N.Beds = "Number of Beds",
  Avg.Pat = "Average No. of Patients",
  Avg.Nur = "Average Nurses Employed",
  Pct.Ser.Fac = "% of Available Facilities",
  Med.Sc.Aff = "Med School Affiliation",
  Region = "Hospital Region"
)

plot_data <- hospital %>%
  select(all_of(c(response, predictors))) %>%
  pivot_longer(cols = all_of(predictors), names_to = "Predictor", values_to = "Value")

ggplot(plot_data, aes(x = Value, y = .data[[response]])) +
  geom_smooth(method = "lm", color = "steelblue", se = TRUE) +
  geom_point(color = "darkblue", alpha = 0.6) +
  facet_wrap(~ Predictor, scales = "free_x", ncol = 5,
             labeller = labeller(Predictor = label_map)) +
  theme_minimal() +
  labs(
    x = NULL,
    y = "Length of Stay",
    title = "Length of Stay vs. Predictors"
  )+
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```



  **Log-Linear Plots:**  In these plots, we logged the response variable "Length of Stay" vs. the rest of the parameters, and didn't notice any change in distributions of the charts.
  
```{r testplots2, echo=FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)

set.seed(123)

response <- "log_Lgth.of.Sty"
predictors <- c("Age", "Inf.Risk", "R.Cul.Rat", "R.CX.ray.Rat", "N.Beds", "Avg.Pat", "Avg.Nur", "Pct.Ser.Fac", "Med.Sc.Aff", "Region")

label_map <- c(
  Age = "Patient Age",
  Inf.Risk = "Infection Risk",
  R.Cul.Rat = "Routine Culturing Ratio",
  R.CX.ray.Rat = "Routine Chest X-Ray Ratio",
  N.Beds = "Number of Beds",
  Avg.Pat = "Average No. of Patients",
  Avg.Nur = "Average Nurses Employed",
  Pct.Ser.Fac = "% of Available Facilities",
  Med.Sc.Aff = "Med School Affiliation",
  Region = "Hospital Region"
)

plot_data <- hospital %>%
  select(all_of(c(response, predictors))) %>%
  pivot_longer(cols = all_of(predictors), names_to = "Predictor", values_to = "Value")

ggplot(plot_data, aes(x = Value, y = .data[[response]])) +
  geom_smooth(method = "lm", color = "steelblue", se = TRUE) +
  geom_point(color = "darkred", alpha = 0.6) +
  facet_wrap(~ Predictor, scales = "free_x", ncol = 5,
             labeller = labeller(Predictor = label_map)) +
  theme_minimal() +
  labs(
    x = NULL,
    y = "Log(Length of Stay)",
    title = "log(Length of Stay) vs. Predictors"
  )+
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```



  **Linear-Log Plots:** In these, we logged the predictor variables except for the two variables "Med School Affiliation" and "Region" since they didn't have distributions that required it. In these plots we can observe more of a linear trend forming between a majority, if not all predictors. We will analyze the models using these logged predictors.
  
```{r testplots3, echo = FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)

set.seed(123)

response <- "Lgth.of.Sty"
predictors <- c("log_Age", "log_Inf.Risk", "log_R.Cul.Rat", "log_R.CX.ray.Rat", "log_N.Beds", "log_Avg.Pat", "log_Avg.Nur", "log_Pct.Ser.Fac", "Med.Sc.Aff", "Region")

label_map <- c(
  "log_Age" = "Patient Age",
  "log_Inf.Risk" = "Infection Risk",
  "log_R.Cul.Rat" = "Routine Culturing Ratio",
  "log_R.CX.ray.Rat" = "Routine Chest X-Ray Ratio",
  "log_N.Beds" = "Number of Beds",
  "log_Avg.Pat" = "Average No. of Patients",
  "log_Avg.Nur" = "Average Nurses Employed",
  "log_Pct.Ser.Fac" = "% of Available Facilities",
  Med.Sc.Aff = "Med School Affiliation",
  Region = "Hospital Region"
)

plot_data <- hospital %>%
  select(all_of(c(response, predictors))) %>%
  pivot_longer(cols = all_of(predictors), names_to = "Predictor", values_to = "Value")

ggplot(plot_data, aes(x = Value, y = .data[[response]])) +
  geom_smooth(method = "lm", color = "steelblue", se = TRUE) +
  geom_point(color = "darkmagenta", alpha = 0.6) +
  facet_wrap(~ Predictor, scales = "free_x", ncol = 5,
             labeller = labeller(Predictor = label_map)) +
  theme_minimal() +
  labs(
    x = NULL,
    y = "Length of Stay",
    title = "Length of Stay vs. log(Predictors)"
  )+
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```



  **Log-Log Plots:** These plots don't appear to exhibit a different trend from the Linear-Log, and therefore we won't utilize the log-log for Objective 1 since we will lose inference on the mean.
  
```{r testplots4, echo = FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)

set.seed(123)

response <- "log_Lgth.of.Sty"
predictors <- c("log_Age", "log_Inf.Risk", "log_R.Cul.Rat", "log_R.CX.ray.Rat", "log_N.Beds", "log_Avg.Pat", "log_Avg.Nur", "log_Pct.Ser.Fac", "Med.Sc.Aff", "Region")

label_map <- c(
  "log_Age" = "Patient Age",
  "log_Inf.Risk" = "Infection Risk",
  "log_R.Cul.Rat" = "Routine Culturing Ratio",
  "log_R.CX.ray.Rat" = "Routine Chest X-Ray Ratio",
  "log_N.Beds" = "Number of Beds",
  "log_Avg.Pat" = "Average No. of Patients",
  "log_Avg.Nur" = "Average Nurses Employed",
  "log_Pct.Ser.Fac" = "% of Available Facilities",
  Med.Sc.Aff = "Med School Affiliation",
  Region = "Hospital Region"
)

plot_data <- hospital %>%
  select(all_of(c(response, predictors))) %>%
  pivot_longer(cols = all_of(predictors), names_to = "Predictor", values_to = "Value")

ggplot(plot_data, aes(x = Value, y = .data[[response]])) +
  geom_smooth(method = "lm", color = "steelblue", se = TRUE) +
  geom_point(color = "darkcyan", alpha = 0.6) +
  facet_wrap(~ Predictor, scales = "free_x", ncol = 5,
             labeller = labeller(Predictor = label_map)) +
  theme_minimal() +
  labs(
    x = NULL,
    y = "log(Length of Stay)",
    title = "log(Length of Stay) vs. log(Predictors)"
  )+
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```




## Objective 1: Infection Risk vs. Avg. Length of Stay

  As stated previously in the introduction, the goal of Objective 1 is to determine whether a hospital's *__infection risk__* is significantly associated with the *__average length__* of patient stay, after accounting for other potentially influential factors.
  
  We will use automatic feature selection techniques such as lasso method, and stepwise functions (forward, backward, both) in addition to traditional multiple linear regression with all predictors to determine statistical significance of infection rate on average hospital stay duration while accounting for the other variables.
  
  First we created a model with all of the non-transformed variables to statistically confirm relationships that we saw in the graphs previously when holding all other predictors constant.
  
```{r obj1.1, echo = FALSE, message = FALSE, warning = FALSE}
library(dplyr)
library(car)
library(gtsummary)
library(tibble)

set.seed(123)

response <- "Lgth.of.Sty"
#Predictors that ignore logged predictors

predictors <- names(hospital) %>%
  setdiff(response) %>%
  setdiff(grep("log|Lgth", names(hospital), ignore.case = TRUE, value = TRUE))

predictors <- c(predictors, "Region")

#Model
model1 <- lm(data = hospital, formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))))

#Parameter Estimate
parameter_table <- tbl_regression(model1, conf.level = 0.95, estimate_fun = ~style_number(.x, digits = 3),
                      pvalue_fun = ~style_pvalue(.x, digits = 3),
                      intercept = TRUE)|> add_vif()
parameter_table

```

AIC of no transformation predictors:

```{r obj1.1 AIC,echo = FALSE, message = FALSE, warning = FALSE }
AIC<-AIC(model1)
print(AIC)
```

Similar to the linear-linear plots we can see clustering on the lower range of x-values for a majority of the predictors, which indicates that the transformations we contemplated could be necessary.

```{r obj1.1 res, echo = FALSE, message = FALSE, warning = FALSE}
#Plot Residual Data
par(mfrow= c(2,2))
plot(model1)
```


Next we ran a model with the logged predictors to determine if the observed higher linear trend were more statistically significant when holding all other parameters constant.

```{r obj1.2, echo = FALSE, message = FALSE, warning = FALSE}
library(dplyr)
library(car)

set.seed(123)

response <- "Lgth.of.Sty"

#Predictors that only chooses logged variables
predictors <- names(hospital) %>%
  grep("log", ., ignore.case = TRUE, value = TRUE) %>%
  setdiff(grep("Lgth|length", ., ignore.case = TRUE, value = TRUE)) %>%
  setdiff(response)


predictors <- c(predictors, "Region")

model2 <- lm(data = hospital, formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))))

parameter_table <- tbl_regression(model2, conf.level = 0.95, estimate_fun = ~style_number(.x, digits = 3),
                      pvalue_fun = ~style_pvalue(.x, digits = 3),
                      intercept = TRUE)|> add_vif()
parameter_table
```


AIC of logged predictors model:
```{r AIC2}
AIC(model2)
```

As you can see from these residuals they are more random and more of a random point cloud and less clustered.

```{r obj1.2 res, echo=FALSE, warning=FALSE, message=FALSE}
#Plot Residual Data
par(mfrow= c(2,2))
plot(model2)
```


  **Automatic Feature Selection:** The team chose to use the lasso function recenetly learned in MSDS 6372 to find the optimal penalty term and automatically select the predictor terms which are below:

```{r mlr1, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(123)

predictors <- names(hospital) %>%
  setdiff(grep("log|Lgth|Age|ID", names(hospital), ignore.case = TRUE, value = TRUE))

#Model
formula <- as.formula(paste("Lgth.of.Sty ~", paste(predictors, collapse = " + ")))
x <- model.matrix(formula, data = hospital)

library(glmnet)
set.seed(1234)

cv.out=cv.glmnet(x,y,alpha=1)
plot(cv.out)
bestlambda<-cv.out$lambda.1se
coef(cv.out,s=bestlambda)
```


  **Automatic Feature Selection of Linear-Log**

```{r mlr2, echo = FALSE, message = FALSE, warning = FALSE}
library(dplyr)
library(glmnet)

set.seed(123)

#Response
response <- "Lgth.of.Sty"

#Predictors
predictors <- names(hospital) %>%
  grep("log",., names(hospital), ignore.case = TRUE, value = TRUE) %>% 
   setdiff(grep("Lgth|ID", ., ignore.case = TRUE, value = TRUE))

predictors <- c(predictors, "Region")

#Model
formula <- as.formula(paste("Lgth.of.Sty ~", paste(predictors, collapse = " + ")))
x <- model.matrix(formula, data = hospital)
y=hospital$Lgth.of.Sty

#Auto Selection
library(glmnet)
set.seed(1234)

cv.out=cv.glmnet(x,y,alpha=1)
plot(cv.out)
bestlambda<-cv.out$lambda.1se
coef(cv.out,s=bestlambda)
```


## Automatic Feature Selection

  **Forward Selection**
```{r forward, echo=FALSE, message=FALSE, warning = FALSE}
library(olsrr)

set.seed(123)

names(hospital) <- gsub("\\(|\\)", "_", names(hospital))
names(hospital) <- gsub("__", "_", names(hospital)) 

#Response
response <- "Lgth.of.Sty"

#Predictors that only choose logged variables
predictors <- names(hospital) %>%
  grep("log", ., ignore.case = TRUE, value = TRUE) %>%
  setdiff(grep("Lgth", ., ignore.case = TRUE, value = TRUE)) %>%
  setdiff(response)

predictors <- c(predictors, "Region")

#Model formula from response vs. predictors above
formula <- as.formula(paste(response, "~", paste(predictors, collapse = " + ")))

#Stepwise Model
stepwise <- lm(formula ,data = hospital)

#Forward
ols_step_forward_p(stepwise, p_val = 0.05, details = FALSE)
```

  **Backward Selection**

```{r step_backward, echo=FALSE, message=FALSE, warning = FALSE}
set.seed(123)

#Stepwise Backward Selection
ols_step_backward_p(stepwise, p_val = 0.05, details = FALSE)
```

  **Stepwise Feature Selection**

```{r stepwise, echo=FALSE, message=FALSE, warning = FALSE}
library(caret)
#Stepwise
set.seed(123)

#Stepwise Both Selection
ols_step_both_p(stepwise, p_enter = 0.05, p_remove = 0.05, details = FALSE)
```


## Objective 1: Infection Rate

```{r final.model, echo = FALSE, message = FALSE, warning = FALSE}
library(dplyr)
library(car)
library(caret)

set.seed(123)

response <- "Lgth.of.Sty"
predictors1 <- "log_Age + log_Inf.Risk + log_R.CX.ray.Rat + log_Avg.Pat + log_Avg.Nur + Region"
predictors2 <- "log_Age + Inf.Risk + R.CX.ray.Rat + Avg.Pat + Avg.Nur + Region"

final.model <- lm(as.formula(paste(response, "~", predictors2)), data=hospital)


parameter_table <- tbl_regression(final.model, conf.level = 0.95, estimate_fun = ~style_number(.x, digits = 3),
                      pvalue_fun = ~style_pvalue(.x, digits = 3),
                      intercept = TRUE)|> add_vif()
parameter_table
```


```{r final.residuals}
#Plot Data
par(mfrow= c(2,2))
plot(final.model)
```


 **Final Model Validation Statistics**
```{r final.validation, echo = FALSE, warning = FALSE, message=FALSE}
#Train/Test/Validation
train_control <- trainControl(method="repeatedcv",number=5, repeats=10)
final.model.train <- train(as.formula(paste(response, "~", predictors2)), data=hospital, trControl=train_control, method="lm")
final.model.train

```